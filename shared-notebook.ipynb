{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fa2b4de",
   "metadata": {},
   "source": [
    "# COM3029 Coursework 2 - Group 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bcaf4a",
   "metadata": {},
   "source": [
    "## Research of Model Serving Options\n",
    "\n",
    "Should this be in the report instead?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644389ec",
   "metadata": {},
   "source": [
    "## Web Service\n",
    "\n",
    "The Flask web server script from `webserver.py` is shown below, and has been adapted to run in this notebook if necessary. Running the script manually is possible with the `waitress-serve --listen=localhost:5000 webserver:app` console command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c552b95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "from transformers import AutoTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"model\")\n",
    "model = BertForSequenceClassification.from_pretrained(\"model\")\n",
    "\n",
    "labels = [\"admiration\", \"amusement\", \"anger\", \"annoyance\", \"curiosity\", \"disapproval\", \"gratitude\", \"joy\", \"love\", \"optimism\", \"remorse\", \"sadness\", \"surprise\", \"neutral\"]\n",
    "\n",
    "def predict_label(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "    outputs = model(**inputs)\n",
    "    \n",
    "    label_index = torch.argmax(outputs.logits, dim=1).item()\n",
    "\n",
    "    return labels[label_index]\n",
    "    \n",
    "# Logging\n",
    "import json\n",
    "import logging\n",
    "from logging.config import dictConfig\n",
    "from datetime import datetime\n",
    "\n",
    "dictConfig({\n",
    "    \"version\": 1,\n",
    "    \"formatters\": {\n",
    "        \"default\": {\n",
    "            \"format\": \"%(message)s\",\n",
    "        }\n",
    "    },\n",
    "    \"handlers\": {\n",
    "        \"file\": {\n",
    "            \"class\": \"logging.FileHandler\",\n",
    "            \"filename\": \"predictions.txt\",\n",
    "            \"formatter\": \"default\",\n",
    "        },\n",
    "    },\n",
    "    \"root\": {\"level\": \"INFO\", \"handlers\": [\"file\"]},\n",
    "})\n",
    "\n",
    "# Prevent regular app messages getting logged.\n",
    "logging.getLogger(\"werkzeug\").disabled = True\n",
    "\n",
    "# Use Python's structured logging to make it machine-parseable.\n",
    "class LogMsg(object):\n",
    "    def __init__(self, text, prediction):\n",
    "        self.text = text\n",
    "        self.prediction = prediction\n",
    "        self.time = datetime.now().strftime('%Y-%m-%d %H:%M:%S:%f')\n",
    "\n",
    "    def __str__(self):\n",
    "        return json.dumps({'time': self.time, 'text': self.text, 'prediction': self.prediction})\n",
    "    \n",
    "class LogMsgInputFormat400Error(object):\n",
    "    def __init__(self):\n",
    "        self.time = datetime.now().strftime('%Y-%m-%d %H:%M:%S:%f')\n",
    "\n",
    "    def __str__(self):\n",
    "        return json.dumps({'time': self.time, 'error': \"The message must be JSON in the form json={'comment': string_to_predict}.\"})\n",
    "\n",
    "# Webserver\n",
    "from flask import Flask, request\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route(\"/\", methods=['GET', 'POST'])\n",
    "def get_prediction():\n",
    "    if request.method == 'GET':\n",
    "        return \"To receive predictions, send a POST request in the form json={'comment': string_to_predict}.\"\n",
    "    else:\n",
    "        if ((type(request.json) != dict) or (list(request.json.keys()) != ['comment']) or (type(request.json['comment']) != str) or (len(request.json[\"comment\"])==0)):\n",
    "            app.logger.info(LogMsgInputFormat400Error())\n",
    "            return json.dumps({\"success\": False, \"error\":\"The message must be JSON in the form json={'comment': string_to_predict}.\"}), 400\n",
    "        comment_text = request.json['comment']\n",
    "        prediction = predict_label(comment_text)\n",
    "        app.logger.info(LogMsg(comment_text, prediction))\n",
    "        return json.dumps({\"success\": True, \"prediction\": prediction})\n",
    "\n",
    "\n",
    "########################################################################\n",
    "##       Notebook only. Remove this to run as a normal .py script.    ##\n",
    "########################################################################\n",
    "\n",
    "from waitress import serve\n",
    "from IPython.lib import backgroundjobs\n",
    "\n",
    "def serve_webserver():\n",
    "    serve(app, host='127.0.0.1', port=5000)\n",
    "\n",
    "server = backgroundjobs.BackgroundJobManager()\n",
    "server.new(serve_webserver)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb92b6fb",
   "metadata": {},
   "source": [
    "And a quick test to make sure it is running and receiving requests properly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bfef7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To receive predictions, send a POST request in the form json={'comment': string_to_predict}.\n",
      "{\"success\": true, \"prediction\": \"neutral\"}\n",
      "{\"success\": true, \"prediction\": \"neutral\"}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "print(requests.get('http://127.0.0.1:5000/').text)\n",
    "\n",
    "def send_prediction_request(string_to_predict):\n",
    "    return requests.post('http://127.0.0.1:5000/', json={'comment': string_to_predict}).text\n",
    "\n",
    "print(send_prediction_request('test comment 1'))\n",
    "print(send_prediction_request('test comment 2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0746adc",
   "metadata": {},
   "source": [
    "## Endpoint Testing\n",
    "\n",
    "### Unit Tests\n",
    "\n",
    "The command below runs the unit tests contained within the `test.py` file. This requires that the webserver is running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676f105c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m unittest "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdba2ed8",
   "metadata": {},
   "source": [
    "### Model Accuracy\n",
    "\n",
    "This test uses 50 comments from the GoEmotions testing dataset to estimate the accuracy of the model. The transformer model used in our web service should achieve an accuracy of around 60-65%. This is not intended to be a thorough test, but simply to establish that the deployed model is performing at the expected level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ace0720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import datasets\n",
    "from tqdm import tqdm\n",
    "\n",
    "dataset = datasets.load_dataset(\"go_emotions\")\n",
    "\n",
    "# Maps all unchosen labels to their most similar counterpart.\n",
    "label_mappings = [\n",
    "    'admiration', 'amusement', 'anger', 'annoyance', 'admiration', 'optimism', 'curiosity',\n",
    "    'curiosity', 'optimism', 'sadness', 'disapproval', 'annoyance', 'sadness', 'joy',\n",
    "    'sadness', 'gratitude', 'sadness', 'joy', 'love', 'sadness', 'optimism',\n",
    "    'admiration', 'admiration', 'gratitude', 'remorse', 'sadness', 'surprise', 'neutral'\n",
    "]\n",
    "\n",
    "count = 50\n",
    "correct = 0\n",
    "for i in tqdm(range(count)):\n",
    "    choice = random.choice(dataset['test'])\n",
    "    prediction = requests.post('http://127.0.0.1:5000/', json={'comment': choice['text']}).json()['prediction']\n",
    "    \n",
    "    if prediction in [label_mappings[x] for x in choice['labels']]:\n",
    "        correct += 1\n",
    "        \n",
    "print(\"Correct: \" + str(correct) + \"    Incorrect: \" + str(count - correct))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f28bfd",
   "metadata": {},
   "source": [
    "## Service Performance & Stress Testing\n",
    "\n",
    "The stress testing script is run from the command line once the web service is running, as shown here:\n",
    "\n",
    "`python stress_test.py -u 50 -r 5 -l 30`\n",
    "\n",
    "The contents of this file is shown below for reference:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e369c2",
   "metadata": {},
   "source": [
    "```python\n",
    "import gevent\n",
    "from locust import HttpUser, task, events\n",
    "from locust.env import Environment\n",
    "from locust.stats import stats_printer, stats_history, StatsCSVFileWriter\n",
    "from locust.log import setup_logging\n",
    "\n",
    "from locustfile import StressTest\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument(\"-u\", \"--user_count\", dest=\"user_count\", help=\"How many users to be created during a spawn\", type=int, default=1)\n",
    "    parser.add_argument(\"-r\", \"--spawn_rate\", dest=\"spawn_rate\", help=\"How many groups of users should be created every second\", type=int, default=1)\n",
    "    parser.add_argument(\"-l\", \"--length\", dest=\"duration\", help=\"How long the stress test should last for\", type=int, default=30)\n",
    "\n",
    "    stress_args = parser.parse_args()\n",
    "\n",
    "\n",
    "    setup_logging(\"INFO\", None)\n",
    "\n",
    "\n",
    "    # setup Environment and Runner\n",
    "    env = Environment(user_classes=[StressTest], events=events)\n",
    "    runner = env.create_local_runner()\n",
    "\n",
    "    # start a WebUI instance\n",
    "    web_ui = env.create_web_ui(\"127.0.0.1\", 8089)\n",
    "\n",
    "    logging = StatsCSVFileWriter(environment=env, base_filepath='./', full_history=True, percentiles_to_report=[90.0])\n",
    "\n",
    "    # execute init event handlers (only really needed if you have registered any)\n",
    "    env.events.init.fire(environment=env, runner=runner, web_ui=web_ui)\n",
    "\n",
    "    # start a greenlet that periodically outputs the current stats\n",
    "    gevent.spawn(stats_printer(env.stats))\n",
    "\n",
    "    gevent.spawn(logging)\n",
    "\n",
    "    # start a greenlet that save current stats to history\n",
    "    gevent.spawn(stats_history, env.runner)\n",
    "\n",
    "    # start the test\n",
    "    runner.start(user_count=stress_args.user_count, spawn_rate=stress_args.spawn_rate)\n",
    "\n",
    "    # in duration seconds stop the runner\n",
    "    gevent.spawn_later(stress_args.duration, lambda: runner.quit())\n",
    "\n",
    "    # wait for the greenlets\n",
    "    runner.greenlet.join()\n",
    "\n",
    "    # stop the web server for good measures\n",
    "    web_ui.stop()\n",
    "\n",
    "    graph_stats = pd.read_csv('_stats_history.csv')\n",
    "    graph_stats = graph_stats[graph_stats['Name'] == 'Aggregated']\n",
    "    x_axis = graph_stats['Timestamp']\n",
    "    x_axis = x_axis - x_axis.min()\n",
    "\n",
    "    target_metrics = ['Requests/s','Failures/s','Total Request Count','Total Failure Count','Total Average Response Time']\n",
    "\n",
    "    for metric in target_metrics:\n",
    "        y_axis = graph_stats[metric].astype(float)\n",
    "\n",
    "        plt.plot(list(x_axis.values), list(y_axis.values))\n",
    "        plt.title(metric)\n",
    "        save_name = metric.replace('/', '_per_')\n",
    "        plt.savefig(f'{save_name}.png')\n",
    "        plt.clf()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09f2f16",
   "metadata": {},
   "source": [
    "## Monitoring Capabilities\n",
    "\n",
    "In order to monitor the user input and predictions of the webservice, the server uses Python's `logging` library to log to a file. For every prediction request made by each user, the time, input text, and predicted label is written as JSON to the `predictions.txt` log file, an example snippet of which is shown here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae9cbd2",
   "metadata": {},
   "source": [
    "```json\n",
    "{\"time\": \"2023-05-23 00:58:45:748136\", \"text\": \"literally I feel like crying\", \"prediction\": \"sadness\"}\n",
    "{\"time\": \"2023-05-23 00:58:46:135930\", \"text\": \"i love this subreddit\", \"prediction\": \"love\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4969991f",
   "metadata": {},
   "source": [
    "JSON is used so that the log file can be parsed programatically and used by a different service, if if ever becomes necessary. This structured logging is implemented using a custom class to store all the necessary data. There is also a class to log error messages, for when the user sends invalid text. Both of these are shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7801fba6",
   "metadata": {},
   "source": [
    "```python\n",
    "class LogMsg(object):\n",
    "    def __init__(self, text, prediction):\n",
    "        self.text = text\n",
    "        self.prediction = prediction\n",
    "        self.time = datetime.now().strftime('%Y-%m-%d %H:%M:%S:%f')\n",
    "\n",
    "    def __str__(self):\n",
    "        return json.dumps({'time': self.time, 'text': self.text, 'prediction': self.prediction})\n",
    "    \n",
    "class LogMsgInputFormat400Error(object):\n",
    "    def __init__(self):\n",
    "        self.time = datetime.now().strftime('%Y-%m-%d %H:%M:%S:%f')\n",
    "\n",
    "    def __str__(self):\n",
    "        return json.dumps({'time': self.time, 'error': \"The message must be JSON in the form json={'comment': string_to_predict}.\"})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88edfce4",
   "metadata": {},
   "source": [
    "Logging a regular request and an invalid request are then done like so:\n",
    "\n",
    "```python\n",
    "# Invalid request:\n",
    "app.logger.info(LogMsgInputFormat400Error())\n",
    "\n",
    "# Valid request:\n",
    "app.logger.info(LogMsg(comment_text, prediction))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db164eb9",
   "metadata": {},
   "source": [
    "## CI/CD Pipeline\n",
    "\n",
    "CI/CD for this web service is performed using the `ci-cd-script.sh` bash script, the contents of which is shown below. This script first calls the `build-and-save-model.py` python script, which will do all of the training for the new model and save it and the tokenizer config to the `./model` directory. Once that has finished, the web service is started in the background as normal, and then the unit tests are run. This ensures that the behaviour of the new model is still correct. Finally, the web service is killed and the new model is committed to the Git repository with a commit labelled for the current date and time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da426103",
   "metadata": {},
   "source": [
    "```bash\n",
    "#!/bin/bash\n",
    "\n",
    "echo \"--- Running CI/CD script ---\"\n",
    "\n",
    "# Build and save the model to the ./model directory.\n",
    "echo \"Training and saving model...\"\n",
    "python3 ./build-and-save-model.py\n",
    "\n",
    "# Begin the webserver in the background.\n",
    "echo \"Starting webservice...\"\n",
    "waitress-serve --listen=localhost:5000 webserver:app &\n",
    "\n",
    "# Allow time for the webserver to start up.\n",
    "sleep 3\n",
    "\n",
    "# Run unit tests to ensure the new model is functioning.\n",
    "echo \"Running unit tests...\"\n",
    "python3 -m unittest\n",
    "\n",
    "# Kill the webserver.\n",
    "echo \"Exiting...\"\n",
    "kill %%\n",
    "\n",
    "git_datetime=$(date +\"%Y-%m-%d %T\")\n",
    "\n",
    "# Push the model changes to Git.\n",
    "git add .\n",
    "git commit -m \"[CI/CD]: ${git_datetime}\"\n",
    "git push\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983c29ac",
   "metadata": {},
   "source": [
    "An example output for a run of this script is shown here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caaf82d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
